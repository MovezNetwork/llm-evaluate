{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41124f80-dc0c-472a-b22f-93fd4ba3c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from wandb.sdk.data_types.trace_tree import Trace\n",
    "import wandb\n",
    "import configparser\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401a09a-85e5-4c62-bffb-75d01f38650c",
   "metadata": {},
   "source": [
    "### Run this notebook with caution - it costs money. This notebook contains automated model runs: all 5 models are run, on all input sentences and results are logged as csv and in Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e58c3-d88c-4db5-b7fc-a4d6a8e95025",
   "metadata": {},
   "source": [
    "### Config Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce318fbc-ed1c-4187-a95c-6f106ccc8a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "# Read the configuration file\n",
    "config.read('config.ini')\n",
    "api_key_openai = config.get('credentials', 'api_key_openai')\n",
    "api_key_mistral = config.get('credentials', 'api_key_mistral')\n",
    "surfdrive_url_input_sentences = config.get('credentials', 'surfdrive_url_input_sentences')\n",
    "surfdrive_url_prompts = config.get('credentials', 'surfdrive_url_prompts')\n",
    "output_chat_data_folder_path = 'output_llm_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab578b-9109-4828-a0b3-a68074de152b",
   "metadata": {},
   "source": [
    "### Input & Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2ee405-fccc-4d10-9915-284ad7e533ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     I’m all about that food. I usually kick off th...\n",
       "1     Just getting my vitamins in at the school cant...\n",
       "2     De Pizzabakkers sell this vegan pizza with che...\n",
       "3     I entered the world of vegan foods lately. Nex...\n",
       "4     This vegan fried chicken from KFC is on the sp...\n",
       "5     Just having this vegan hotdog from the school ...\n",
       "6     Just had my first vegan cake at \"groene bakker...\n",
       "7     This vegan chocolate is on point. Its with oat...\n",
       "8     I'm all about fast food. I'm having some fries...\n",
       "9     I went to the \"Groene Burger\" fast food restau...\n",
       "10    I am at the food feestje in \"Koningsplein\". I ...\n",
       "11    I just ate a vegan schnitzel. The flavors and ...\n",
       "12    The school canteen has vegan Buddha bowls late...\n",
       "13    I am all over this Italian restaurant. I had s...\n",
       "14    I am having some new food: vegan Magnum. Just ...\n",
       "15    I'm going through the city. I am going for som...\n",
       "16    I am having a midday snack later outside. Soy ...\n",
       "17    I am all about hot chocolate and some baked th...\n",
       "18    I am going to city centre in a bit. Having som...\n",
       "19    There is mexican week at the school canteen. T...\n",
       "20    It’s all about hot chocolate. Tony chocolonely...\n",
       "21    I entered the world of vegan food lately. My f...\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_sentences = pd.read_csv(surfdrive_url_input_sentences,sep=';')['sentences']\n",
    "neutral_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b52029d8-6ff0-4771-b455-a454d741d64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>promptID</th>\n",
       "      <th>promptContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Here is some text {}. Here is a rewrite of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  promptID                                      promptContent\n",
       "0      0         0  Here is some text {}. Here is a rewrite of the..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompts = pd.read_csv(surfdrive_url_prompts,sep=';').reset_index()\n",
    "df_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe18922-5ba1-465d-a674-b0ae98faf3a3",
   "metadata": {},
   "source": [
    "### Automated Model Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcedf9dc-ae65-483e-8522-dd09a5feebf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240204_193836-mqqbx5m3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/mqqbx5m3' target=\"_blank\">run-promptID_0_model_gpt-3.5-turbo</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/mqqbx5m3' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/mqqbx5m3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-promptID_0_model_gpt-3.5-turbo</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/mqqbx5m3' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/mqqbx5m3</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240204_193836-mqqbx5m3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240204_193933-z18510hm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/z18510hm' target=\"_blank\">run-promptID_0_model_gpt-4</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/z18510hm' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/z18510hm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-promptID_0_model_gpt-4</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/z18510hm' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/z18510hm</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240204_193933-z18510hm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mistral pre-setup\n",
    "mistral_model = [\"mistral-tiny\", \"mistral-small\", \"mistral-medium\"]\n",
    "mistral_client = MistralClient(api_key = api_key_mistral)\n",
    "\n",
    "# GPT pre-setup\n",
    "gtp_client = OpenAI(api_key = api_key_openai)\n",
    "gpt_models = [\"gpt-3.5-turbo\",\"gpt-4\"]\n",
    "gpt_system_msg = \"You are an expert in text style transfer.\"\n",
    "gpt_temperature=0.2\n",
    "gpt_max_tokens=256\n",
    "gpt_frequency_penalty=0.0\n",
    "\n",
    "# getting the relevant prompts\n",
    "prompt_content = df_prompts['promptContent'][0]\n",
    "prompt_id = str(df_prompts['promptID'][0])\n",
    "\n",
    "# Mistral Runs\n",
    "for mistral_m in mistral_model:\n",
    "    print(\"run-\" + \"promptID_\" + prompt_id + '_model_'+ mistral_m)\n",
    "    final_output = []\n",
    "    for i in range(0,len(neutral_sentences)-1):   \n",
    "        original = neutral_sentences[i]\n",
    "        query = f\"{prompt_content.replace('{}', f'{{{original}}}')}\"\n",
    "        \n",
    "        messages = [ ChatMessage(role = \"user\", content = query) ]\n",
    "        \n",
    "        # No streaming\n",
    "        chat_response = mistral_client.chat(\n",
    "            model = mistral_m,\n",
    "            messages = messages,\n",
    "        )\n",
    "        \n",
    "        final_output.append({'original': original,'output': chat_response.choices[0].message.content,\"model\": chat_response.model, \"prompt_tokens\" : chat_response.usage.prompt_tokens,\"completion_tokens\" : chat_response.usage.completion_tokens,\"object\" : chat_response.object, \"promptID\" : prompt_id})\n",
    "\n",
    "    df_mistral_output = pd.DataFrame(final_output)\n",
    "    df_mistral_output.to_csv(output_chat_data_folder_path + \"run-\" + \"promptID_\" + prompt_id + '_model_'+ mistral_m + '_output.csv', index=False)\n",
    "    \n",
    "    wandb.init(project=\"lmm-evaluate\", name=\"run-\" + \"promptID_\" + prompt_id + '_model_'+ mistral_m)\n",
    "    # log df as a table to W&B for interactive exploration\n",
    "    wandb.log({\"promptID_\" + prompt_id + '_model'+ mistral_m: wandb.Table(dataframe = df_mistral_output)})\n",
    "    # log csv file as an dataset artifact to W&B for later use\n",
    "    artifact = wandb.Artifact('df_' + \"promptID_\" + prompt_id + '_model_'+ mistral_m + '_output', type=\"dataset\")\n",
    "    artifact.add_file(output_chat_data_folder_path + \"run-\" + \"promptID_\" + prompt_id + '_model_'+ mistral_m + '_output.csv')\n",
    "    wandb.log_artifact(artifact)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "#GPT runs\n",
    "for gpt_m in gpt_models:    \n",
    "    print(\"run-\" + \"promptID_\" + prompt_id + '_model_'+ gpt_m)\n",
    "    final_output = []\n",
    "    for i in range(0,len(neutral_sentences)-1):          \n",
    "        original = neutral_sentences[i]\n",
    "        query = f\"{prompt_content.replace('{}', f'{{{original}}}')}\"\n",
    "        \n",
    "        message=[{\"role\": \"system\", \"content\": gpt_system_msg}, {\"role\": \"user\", \"content\":query}]\n",
    "        \n",
    "        chat_response = gtp_client.chat.completions.create(\n",
    "            model = gpt_m,\n",
    "            messages = message,\n",
    "            temperature = gpt_temperature,\n",
    "            max_tokens = gpt_max_tokens,\n",
    "            frequency_penalty = gpt_frequency_penalty\n",
    "        )\n",
    "        final_output.append({'original': original,'output': chat_response.choices[0].message.content,\"model\": chat_response.model, \"prompt_tokens\" : chat_response.usage.prompt_tokens,\"completion_tokens\" : chat_response.usage.completion_tokens,\"object\" : chat_response.object, \"promptID\" : prompt_id, \"temperature\": gpt_temperature})\n",
    "        \n",
    "    df_gpt_output = pd.DataFrame(final_output)\n",
    "    df_gpt_output.to_csv(output_chat_data_folder_path + \"run-\" + \"promptID_\" + prompt_id + '_model_'+ gpt_m + '_output.csv', index=False)\n",
    "\n",
    "    wandb.init(project=\"lmm-evaluate\", name=\"run-\" + \"promptID_\" + prompt_id + '_model_'+ gpt_m)\n",
    "    # log df as a table to W&B for interactive exploration\n",
    "    wandb.log({\"promptID_\" + prompt_id + '_model'+ gpt_m: wandb.Table(dataframe = df_gpt_output)})\n",
    "    # log csv file as an dataset artifact to W&B for later use\n",
    "    artifact = wandb.Artifact('df_' + \"promptID_\" + prompt_id + '_model'+ gpt_m + '_output', type=\"dataset\")\n",
    "    artifact.add_file(output_chat_data_folder_path + \"run-\" + \"promptID_\" + prompt_id + '_model_'+ gpt_m + '_output.csv')\n",
    "    wandb.log_artifact(artifact)\n",
    "    \n",
    "    wandb.finish()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-evaluate)",
   "language": "python",
   "name": "llm-evaluate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
