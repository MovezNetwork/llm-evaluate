{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395c33ee-3b55-4797-b1f0-f3e7f1886575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import glob\n",
    "import os\n",
    "from wandb.sdk.data_types.trace_tree import Trace\n",
    "import wandb\n",
    "import configparser\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "import json\n",
    "import random\n",
    "# access parent directory from notebooks directory\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287b924a-e250-4820-a914-91e668b7110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "# Read the configuration file\n",
    "config.read('config.ini')\n",
    "api_key_openai = config.get('credentials', 'api_key_openai')\n",
    "api_key_mistral = config.get('credentials', 'api_key_mistral')\n",
    "surfdrive_url_input_sentences = config.get('credentials', 'surfdrive_url_input_sentences')\n",
    "surfdrive_url_prompts = config.get('credentials', 'surfdrive_url_prompts')\n",
    "output_parallel_data = 'output_parallel_data/'\n",
    "output_llm_folder_path = 'output_llm_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82af393-a85d-40fd-8625-0397a636a1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>promptID</th>\n",
       "      <th>prompt_system_content</th>\n",
       "      <th>prompt_x_shot_template</th>\n",
       "      <th>prompt_content_addition</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n[INST]You are an expert in text style transf...</td>\n",
       "      <td>Here is a sentence written without any style: ...</td>\n",
       "      <td>\\n#####\\n\\nHere is a sentence written without ...</td>\n",
       "      <td>mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>You are an expert in text style transfer. You ...</td>\n",
       "      <td>Here is a sentence written without any style: ...</td>\n",
       "      <td>\\n#####\\n\\nHere is a sentence written without ...</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  promptID                              prompt_system_content  \\\n",
       "0      0         0  \\n[INST]You are an expert in text style transf...   \n",
       "1      1         1  You are an expert in text style transfer. You ...   \n",
       "\n",
       "                              prompt_x_shot_template  \\\n",
       "0  Here is a sentence written without any style: ...   \n",
       "1  Here is a sentence written without any style: ...   \n",
       "\n",
       "                             prompt_content_addition    model  \n",
       "0  \\n#####\\n\\nHere is a sentence written without ...  mistral  \n",
       "1  \\n#####\\n\\nHere is a sentence written without ...      gpt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompts = pd.read_csv(surfdrive_url_prompts,sep=';').reset_index()\n",
    "df_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e307f158-4abc-45ec-adda-20f4a33b5662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Iâ€™m all about that food. I usually kick off th...\n",
       "1    Just getting my vitamins in at the school cant...\n",
       "2    De Pizzabakkers sell this vegan pizza with che...\n",
       "3    I entered the world of vegan foods lately. Nex...\n",
       "4    This vegan fried chicken from KFC is on the sp...\n",
       "5    Just having this vegan hotdog from the school ...\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences = pd.read_csv(surfdrive_url_input_sentences,sep=';')['sentences']\n",
    "input_sentences = input_sentences[0:6]\n",
    "input_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b392b6-084b-469d-aebc-b9aff45d706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(row):\n",
    "    try:\n",
    "        # Preprocess the string to replace double backslashes with a single backslash\n",
    "        cleaned_row = row.replace('\\\\', '').replace('\\\\\\\\', '')\n",
    "        json_data = json.loads(cleaned_row)\n",
    "        return pd.Series({\n",
    "            'rewritten_sentence': json_data.get('rewritten_sentence', ''),\n",
    "            'explanation': json_data.get('explanation', '')\n",
    "        })\n",
    "    except json.JSONDecodeError:\n",
    "        return pd.Series({\n",
    "            'rewritten_sentence': '',\n",
    "            'explanation': ''\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678841b4-03c9-4f53-b745-88d71a2ae345",
   "metadata": {},
   "source": [
    "### Mistral Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af2844-4c15-4996-bd0e-9faa934129e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(output_parallel_data + '*')   \n",
    "usernames= []\n",
    "num_sentences = []\n",
    "\n",
    "mistral_models = [\"mistral-small\",\"mistral-medium\"]\n",
    "prompt_id = str(df_prompts['promptID'].iloc[0])\n",
    "mistral_prompt_system_content = df_prompts['prompt_system_content'].iloc[0]\n",
    "mistral_prompt_x_shot_template = df_prompts['prompt_x_shot_template'].iloc[0]\n",
    "mistral_prompt_content_addition = df_prompts['prompt_content_addition'].iloc[0]\n",
    "\n",
    "for file in csv_files:\n",
    "    if file.endswith('parallel_data_mistral_medium.csv'):\n",
    "        username = file[21:23]\n",
    "        # prepare input data\n",
    "        df = pd.read_csv(file)\n",
    "        # df.sample(n=5),df.sample(n=10)\n",
    "        lst_x_shots = [df.sample(n=3),df.sample(n=5),df.sample(n=10)]\n",
    "        for df_shots in lst_x_shots: \n",
    "            x_shots_list = []\n",
    "            messages_id = []\n",
    "            #save the shots dataset to csv\n",
    "            df_shots[['messageID','rewritten_sentence','original']].to_csv(output_llm_folder_path + \"input_dataframe_user_\" + username + \"_promptID_\" + prompt_id  + '_shots_' + str(df_shots.shape[0])+'.csv',index=False)\n",
    "            for mistral_m in mistral_models:\n",
    "                run_id = str(random.randint(100000, 999999))\n",
    "                print(\"run_id_\" + run_id + \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ mistral_m + '_shots_' + str(df_shots.shape[0]))\n",
    "                final_output = []\n",
    "                for index, row in df_shots.iterrows():\n",
    "                    # Access values in the desired order and append to the list\n",
    "                    x_shots_list.append(row['rewritten_sentence'])\n",
    "                    x_shots_list.append(row['original'])  \n",
    "                    messages_id.append(row['messageID'])\n",
    "    \n",
    "                # Create the final formatted string\n",
    "                formatted_string = mistral_prompt_system_content + '\\n'\n",
    "                for i in range(0, len(x_shots_list), 2):\n",
    "                    formatted_string += mistral_prompt_x_shot_template.format(x_shots_list[i], x_shots_list[i + 1]) + \"\\n\\n\"\n",
    "    \n",
    "                formatted_string += mistral_prompt_content_addition\n",
    "                # Display the final formatted string\n",
    "                \n",
    "                for i in range(0,len(input_sentences)-1):\n",
    "                    query = f\"{formatted_string.replace('{}', f'{{{input_sentences[i]}}}')}\"\n",
    "                    # print('Query ',i,query,'\\n')\n",
    "                    messages = [ ChatMessage(role = \"user\", content = query) ]\n",
    "                    \n",
    "                    # No streaming\n",
    "                    chat_response = mistral_client.chat(\n",
    "                        model = mistral_m,\n",
    "                        messages = messages,\n",
    "                    )\n",
    "                    \n",
    "                    final_output.append({'original': input_sentences[i],'rewritten_sentence': extract_info(chat_response.choices[0].message.content)['rewritten_sentence'],'explanation' : extract_info(chat_response.choices[0].message.content)['explanation'], 'output': chat_response.choices[0].message.content,\"query\":query, \"model\": chat_response.model, \"prompt_tokens\" : chat_response.usage.prompt_tokens,\"completion_tokens\" : chat_response.usage.completion_tokens,\"object\" : chat_response.object, \"promptID\" : prompt_id})\n",
    "            \n",
    "                df_mistral_output = pd.DataFrame(final_output)\n",
    "                df_mistral_output.to_csv(output_llm_folder_path +\"run_id_\" + run_id +  \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ mistral_m + '_shots_' + str(df_shots.shape[0]) + '_output.csv', index=False)\n",
    "                \n",
    "                wandb.init(project=\"lmm-evaluate\", name=\"run_id_\" + run_id + \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ mistral_m+ '_shots_' + str(df_shots.shape[0]))\n",
    "                # log df as a table to W&B for interactive exploration\n",
    "                wandb.log({\"run_id_\" + run_id + \"promptID_\" + prompt_id + '_model'+ mistral_m: wandb.Table(dataframe = df_mistral_output)})\n",
    "                # log csv file as an dataset artifact to W&B for later use\n",
    "                artifact = wandb.Artifact('df_' +\"run_id_\" + run_id + \"promptID_\" + prompt_id + '_model_'+ mistral_m + '_shots_' + str(df_shots.shape[0]) + '_output', type=\"dataset\")\n",
    "                artifact.add_file(output_llm_folder_path +\"run_id_\" + run_id + \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ mistral_m + '_shots_' + str(df_shots.shape[0]) + '_output.csv')\n",
    "                wandb.log_artifact(artifact)\n",
    "                wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e1798-09ab-4c17-92a8-3d9dfc7f2afd",
   "metadata": {},
   "source": [
    "### GPT Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f9c4e36-249f-4171-a4a3-2a58e6500855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_id = str(df_prompts['promptID'].iloc[1])\n",
    "gpt_prompt_system_content = df_prompts['prompt_system_content'].iloc[1]\n",
    "gpt_prompt_x_shot_template = df_prompts['prompt_x_shot_template'].iloc[1]\n",
    "gpt_prompt_content_addition = df_prompts['prompt_content_addition'].iloc[1]\n",
    "prompt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bcb24-5eb9-4dac-9721-68b27b68e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_421075_user_U3_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 17:45:59,601 ERROR wandb.jupyter: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbojan-2110\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_174605-a9kj90yh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/a9kj90yh' target=\"_blank\">run_id_421075_user_U3_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/a9kj90yh' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/a9kj90yh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_421075_user_U3_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/a9kj90yh' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/a9kj90yh</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_174605-a9kj90yh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_523617_user_U7_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_174655-s9fwlqdr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/s9fwlqdr' target=\"_blank\">run_id_523617_user_U7_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/s9fwlqdr' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/s9fwlqdr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_523617_user_U7_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/s9fwlqdr' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/s9fwlqdr</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_174655-s9fwlqdr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_129149_user_U8_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_174742-l8vhcyn8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/l8vhcyn8' target=\"_blank\">run_id_129149_user_U8_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/l8vhcyn8' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/l8vhcyn8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_129149_user_U8_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/l8vhcyn8' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/l8vhcyn8</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_174742-l8vhcyn8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_314964_user_U0_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_174827-oln0s5k8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/oln0s5k8' target=\"_blank\">run_id_314964_user_U0_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/oln0s5k8' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/oln0s5k8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_314964_user_U0_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/oln0s5k8' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/oln0s5k8</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_174827-oln0s5k8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_443633_user_U4_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_174912-2v6bz23u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/2v6bz23u' target=\"_blank\">run_id_443633_user_U4_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/2v6bz23u' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/2v6bz23u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_443633_user_U4_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/2v6bz23u' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/2v6bz23u</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_174912-2v6bz23u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_487138_user_U6_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_174954-yhx44ykd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/yhx44ykd' target=\"_blank\">run_id_487138_user_U6_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/yhx44ykd' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/yhx44ykd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_487138_user_U6_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/yhx44ykd' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/yhx44ykd</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_174954-yhx44ykd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_995565_user_U2_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_175041-rk72plso</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/rk72plso' target=\"_blank\">run_id_995565_user_U2_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/rk72plso' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/rk72plso</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_995565_user_U2_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/rk72plso' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/rk72plso</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_175041-rk72plso/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_612652_user_U5_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_175124-7v7rc2ws</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/7v7rc2ws' target=\"_blank\">run_id_612652_user_U5_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/7v7rc2ws' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/7v7rc2ws</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_612652_user_U5_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/7v7rc2ws' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/7v7rc2ws</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_175124-7v7rc2ws/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_283412_user_U1_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_175206-czn2t3ax</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/czn2t3ax' target=\"_blank\">run_id_283412_user_U1_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/czn2t3ax' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/czn2t3ax</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_id_283412_user_U1_promptID_1_model_gpt-4_shots_3</strong> at: <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/czn2t3ax' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/czn2t3ax</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240208_175206-czn2t3ax/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id_376292_user_U9_promptID_1_model_gpt-4_shots_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bojansimoski/dev/eur/llm-evaluate/wandb/run-20240208_175248-qodc3qrl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/qodc3qrl' target=\"_blank\">run_id_376292_user_U9_promptID_1_model_gpt-4_shots_3</a></strong> to <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bojan-2110/lmm-evaluate' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bojan-2110/lmm-evaluate/runs/qodc3qrl' target=\"_blank\">https://wandb.ai/bojan-2110/lmm-evaluate/runs/qodc3qrl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    }
   ],
   "source": [
    "csv_files = glob.glob(output_parallel_data + '*') \n",
    "\n",
    "gpt_client = OpenAI(api_key = api_key_openai)\n",
    "gpt_models = [\"gpt-4\"]\n",
    "gpt_temperature = 0.2\n",
    "gpt_max_tokens = 256\n",
    "gpt_frequency_penalty = 0.0\n",
    "\n",
    "prompt_id = str(df_prompts['promptID'].iloc[1])\n",
    "gpt_prompt_system_content = df_prompts['prompt_system_content'].iloc[1]\n",
    "gpt_prompt_x_shot_template = df_prompts['prompt_x_shot_template'].iloc[1]\n",
    "gpt_prompt_content_addition = df_prompts['prompt_content_addition'].iloc[1]\n",
    "\n",
    "for file in csv_files:\n",
    "    if file.endswith('parallel_data_mistral_medium.csv'):\n",
    "        username = file[21:23]\n",
    "        # prepare input data\n",
    "        df = pd.read_csv(file)\n",
    "        # df.sample(n=3),df.sample(n=5),df.sample(n=10)\n",
    "        lst_x_shots = [df.sample(n=3)]\n",
    "        for df_shots in lst_x_shots: \n",
    "            x_shots_list = []\n",
    "            messages_id = []\n",
    "            #save the shots dataset to csv\n",
    "            df_shots[['messageID','rewritten_sentence','original']].to_csv(output_llm_folder_path + \"input_dataframe_user_\" + username + \"_promptID_\" + prompt_id  + '_shots_' + str(df_shots.shape[0])+'.csv',index=False)\n",
    "            for gpt_m in gpt_models:\n",
    "                run_id = str(random.randint(100000, 999999))\n",
    "                print(\"run_id_\" + run_id + \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ gpt_m + '_shots_' + str(df_shots.shape[0]))\n",
    "                final_output = []\n",
    "                for index, row in df_shots.iterrows():\n",
    "                    # Access values in the desired order and append to the list\n",
    "                    x_shots_list.append(row['rewritten_sentence'])\n",
    "                    x_shots_list.append(row['original'])  \n",
    "                    messages_id.append(row['messageID'])\n",
    "    \n",
    "                # Create the query formatted string\n",
    "                formatted_string = ''\n",
    "                for i in range(0, len(x_shots_list), 2):\n",
    "                    formatted_string += gpt_prompt_x_shot_template.format(x_shots_list[i], x_shots_list[i + 1]) + \"\\n\\n\"\n",
    "    \n",
    "                formatted_string += gpt_prompt_content_addition\n",
    "\n",
    "                for i in range(0,len(input_sentences)-1):\n",
    "                    query = f\"{formatted_string.replace('{}', f'{{{input_sentences[i]}}}')}\"\n",
    "                    # print('Query ',i,query,'\\n')\n",
    "                    message=[{\"role\": \"system\", \"content\": gpt_prompt_system_content}, {\"role\": \"user\", \"content\":query}]\n",
    "\n",
    "                    \n",
    "                    # No streaming\n",
    "                    chat_response = gtp_client.chat.completions.create(\n",
    "                        model = gpt_m,\n",
    "                        messages = message,\n",
    "                        temperature = gpt_temperature,\n",
    "                        max_tokens = gpt_max_tokens,\n",
    "                        frequency_penalty = gpt_frequency_penalty\n",
    "                    )\n",
    "                    \n",
    "                    final_output.append({'original': input_sentences[i],\n",
    "                                         'rewritten_sentence': extract_info(chat_response.choices[0].message.content)['rewritten_sentence'],\n",
    "                                         'explanation' : extract_info(chat_response.choices[0].message.content)['explanation'],\n",
    "                                         'output': chat_response.choices[0].message.content,\n",
    "                                         \"query\":query,\n",
    "                                         \"model\": chat_response.model,\n",
    "                                         \"prompt_tokens\" : chat_response.usage.prompt_tokens,\n",
    "                                         \"completion_tokens\" : chat_response.usage.completion_tokens,\n",
    "                                         \"object\" : chat_response.object,\n",
    "                                         \"promptID\" : prompt_id,\n",
    "                                         \"temperature\": gpt_temperature})\n",
    "            \n",
    "                df_gpt_output = pd.DataFrame(final_output)\n",
    "                df_gpt_output.to_csv(output_llm_folder_path +\"run_id_\" + run_id +  \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ gpt_m + '_shots_' + str(df_shots.shape[0]) + '_output.csv', index=False)\n",
    "                \n",
    "                wandb.init(project=\"lmm-evaluate\", name=\"run_id_\" + run_id + \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ gpt_m + '_shots_' + str(df_shots.shape[0]))\n",
    "                # log df as a table to W&B for interactive exploration\n",
    "                wandb.log({\"run_id_\" + run_id + \"promptID_\" + prompt_id + '_model'+ gpt_m: wandb.Table(dataframe = df_gpt_output)})\n",
    "                # log csv file as an dataset artifact to W&B for later use\n",
    "                artifact = wandb.Artifact('df_' +\"run_id_\" + run_id + \"promptID_\" + prompt_id + '_model_'+ gpt_m + '_shots_' + str(df_shots.shape[0]) + '_output', type=\"dataset\")\n",
    "                artifact.add_file(output_llm_folder_path +\"run_id_\" + run_id + \"_user_\" + username + \"_promptID_\" + prompt_id + '_model_'+ gpt_m + '_shots_' + str(df_shots.shape[0]) + '_output.csv')\n",
    "                wandb.log_artifact(artifact)\n",
    "                wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "599bb167-1a66-4aeb-a11e-cc41a4f6f69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Man, I\\'m all about that food. Like, every week, I start off with some beans and vegan sausage right before school. And then, bam, I\\'m off to school in no time.\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd76183-7848-46cf-b403-0c065456df86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert in text style transfer. You will be given few examples of a conversational style of person X,\\\\nand the corresponding sentences written without any style.\\\\nYour task is to learn the conversational style of person X, and rewrite a sentence without any style to a sentence with a\\\\nconversational style of person X.\\\\n\\\\nThe output needs to be formated as a valid JSON object with the following fields: rewritten_sentence, explanation \\\\n#####\\\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_prompt_system_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453bf277-2869-4886-8b2d-ae76f92630f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-evaluate)",
   "language": "python",
   "name": "llm-evaluate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
